---
title: "|"
  | Homework 1: Simple Linear Regression an Logistic Regression
author: "<Furkan Ã–ZELGE (14758028780)>"
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y')`"
output:
  word_document:
    toc: yes
  pdf_document:
    fig_width: 6
    fig_height: 4
    number_sections: yes
    toc: yes
---


```{r setup, include=FALSE, echo=F, warning=F, message=F}
knitr::opts_chunk$set(echo = TRUE)
```

# Part 1: Simple Linear Regression

Exam grades and weekly spent time on self study $x$ (in hours) of 14 statistics students are given in the following table. 

| Self study | 25.0 | 26.2 | 24.9 | 23.7 | 22.8 | 24.6 | 23.6 | 23.0 | 22.5 | 26.2 | 25.8 | 24.0 | 22.1 | 21.7 |
|---------------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|
| Exam Grades      |   63 |   53 |   52 |   46 |   34 |   47 |   43 |   37 |   40 |   45 |   53 |   42 |   32 |   49 |


1. Create a data frame in `R` with the above data. Plot the data with the weekly spent time on self study in the $x$-axis and exam grades on the $y$-axis (You should include labels for your axes and a title for the plot)

2. Obtain the least squares regression line of exam grades on weekly spent time on self study. Interpret your model result (Using the whole data set)

3. Fit the linear model after partitioning your data set into training and testing (round the number of observations when it is necessary). After fitting the model, compare your parameter estimates with the model result in Question 2. Then, make predictions on testing data and compare with the original observations. 

4. Using the `plot` command, comment on the validity of the assumption of the model that you fit in Question 3 (Note before using the `plot` command you may wish to specify a 2x2 graphics window using `par(mfrow = c(2, 2))`).

5. Calculate a $95\%$ confidence interval for the slope regression parameter for the last model you fit in Question 3. (Note that the number of degrees of freedom should be obtained from the `R` output). For this you can use a built-in function in R

# Part 1: Solution

Use the given R-code chunk below to make your calculations and summarize your result thereafter by adding comments on it, 

- MAKE SURE THAT ALL NECESSARY PACKAGES ARE ALREADY INSTALLED and READY TO USE 

- You can use as many as Rcode chunks you want. In the final output, both Rcodes and your ouputs including your comments should appear in an order

```{r}
# FOR REPRODUCIBILITY
set.seed(28780)
# ALERT: YOU NEED TO USE YOUR STUDENT NUMBER LAST 5 DIGITS 
# HERE instead of 442 MAKE SURE THAT YOU CHANGED 
# BEFORE STARTING TO YOUR ANALYSIS
selfStudy <- c(25.0, 26.2, 24.9, 23.7, 22.8, 24.6, 23.6, 23.0, 22.5, 26.2, 25.8, 24.0, 22.1, 21.7)
examGrades <- c(63, 53, 52, 46, 34, 47, 43, 37, 40, 45, 53, 42, 32, 49)
df <- data.frame(selfStudy, examGrades)
# hist()
plot(df$selfStudy,df$examGrades)

# sample mean of x
xbar <- mean( df$selfStudy )

# sample mean of y
ybar <- mean( df$examGrades)

# denumerator for beta1 estimate
tempXX <- sum( (df$selfStudy- xbar)^2 )

# numerator for beta1 estimate
tempXY <- sum( (df$selfStudy- xbar) * (df$examGrades - ybar) )

# estimate of beta1, of slope
beta1_hat <- tempXY / tempXX
beta1_hat
# estimate of beta0, of intercept
beta0_hat <- ybar - beta1_hat * xbar
beta0_hat

# Our linear fit has the form
# mpg \approx beta0_hat + beta1_hat * EG

# For EG = 25.7

EG = beta0_hat + beta1_hat * 25.7
EG
# Use of lm function ------------------------------------------------------

# Use of lm function 
EG_model <- lm(formula = examGrades ~ selfStudy, data = df)  

EG_model
# For more information
summary(EG_model)

abline(EG_model, col = "red")

# ALWAYS START with DATA PARTITIONING
# %80 for training, %20 for testing
# MY STUDENT NUMBER 14758028780
set.seed(28780)
sample.size <- floor(0.80 * nrow(df)) 
train.index <- sample(seq_len(nrow(df)), size = sample.size)

# Partitioning on training and testing
train <- df[train.index, ]
test <- df[-train.index, ]

# MODEL BUILDING
# Simple linear regression 
lm.fit = lm(formula = examGrades ~ selfStudy, data = df) 
summary(lm.fit) 

# Model diagnostic part 
par(mfrow = c(2,2))
plot(lm.fit)

# PREDICTION : Use the testing data
class(lm.fit)
predic_EG <- predict(lm.fit, newdata = test)
head(predic_EG)
head(test$examGrades)
cor(predic_EG, test$examGrades)^2
confint(EG_model , level=0.95)

```
1.2) We got the least squares regression line with EG_model and abline method.. . Some variables are out of our line and messy, but we can still ignore that and still work with it. We can ignore vertical distance. Only the horizontal distance concerns us.
1.3) Our guesses aren't too bad in this.
1.4) Here, linearity is fine. In our changing variance, the residuals are well and homogeneously all over the place.
1.5)Here you may notice that our forecasts were not good.
```{r}

```


# Part 2: Logistic Regression

Consider the available example data set below

```{r}
# install.packages("mlbench")
library(mlbench)
data(BreastCancer)

summary(BreastCancer)
# You can check the details here
# https://www.rdocumentation.org/packages/mlbench/versions/2.1-3/topics/BreastCancer
```

1. Convert your Class variable into a numerical one since you have two classes (benign malignant) you can make it one of them as 0 and the other one is 1

2. Fit a logistic regression model to classify **Class** using Mitoses (DO NOT FORGET TO PARTITION YOUR DATA INTO TRAINING AND TESTING DATA SETS, DO NOT FORGET THAT THIS DATA SET INCLUDES QUALITATIVE PREDICTORS !)

3. Make predictions and compare with the true observations (using TEST DATA SET). Calculate and intepret the Confusion Matrix results

4. Fit a multiple logistic regression to classify **Class** by using more than one predictor

5. Compare simple logistic and multiple logistic regression models using F1-score to make a decision on the best model

# Part 2: Solution

Use the given R-code chunk below to make your calculations and summarize your result thereafter by adding comments on it, 

- MAKE SURE THAT ALL NECESSARY PACKAGES ARE ALREADY INSTALLED and READY TO USE 

- You can use as many as Rcode chunks you want. In the final output, both Rcodes and your ouputs including your comments should appear in an order

```{r}
library(mlbench)
data(BreastCancer)
summary(BreastCancer)
View(BreastCancer)
BreastCancer$Class = factor(BreastCancer$Class, labels = c("0","1"))

# We should start with Data Partitioning
set.seed(28780)
default_idx <- sample(nrow(BreastCancer), 0.80 * nrow(BreastCancer))
# I am declaring training data set
trainingDataSet <- BreastCancer[default_idx, ]
dim(trainingDataSet)
# table(trainingDataSet$default)
# I am declaring testing data set
default_tst <- BreastCancer[-default_idx, ]
dim(default_tst)

model_glm = glm(formula = Class ~ Mitoses, data = trainingDataSet, family = "binomial")
summary(model_glm)
coef(model_glm)

# Prediction part for the fitted model 
# Result of logistic link function by default
head(predict(model_glm))

# Now we can get probabilities by changing the type as response
head(predict(model_glm, type = "response"))

#  these are not predicted probabilities. To obtain the predicted probabilities
head(predict(model_glm, type = "response", newdata = default_tst))

# Note that these are probabilities, not classifications. 
# To obtain classifications, we will need to compare to the correct cutoff value with an ifelse() statement.
# I set it to 0.5 because there are only 2 possibilities. 1 or 0 so we make 0.5.
predict(model_glm, type = "response") > 0.5

# model_glm_pred = ifelse(predict(model_glm, type = "link") > 0, 1, 0)
model_glm_pred = ifelse(predict(model_glm, type = "response") > 0.5, 1, 0)

head(model_glm_pred)
table(model_glm_pred)
# To make a small comparison
# Coming from the original values in training data
table(trainingDataSet$Class)

# Coming from the predicted values over the training data
table(model_glm_pred)

# Training error rate
# For the calculation of basically mean error rate
calc_class_err = function(actual, predicted) 
{
  mean(actual != predicted) 
}

calc_class_err(actual = trainingDataSet$Class, predicted = model_glm_pred)

# You can do a similar thing for testing, you must do indeed !
model_glm_pred = ifelse(predict(model_glm, type = "response", 
                                newdata = default_tst) > 0.5, 1, 0)

head(model_glm_pred)
length(model_glm_pred)
length(predict(model_glm, type = "response", 
               newdata = default_tst))

calc_class_err(actual = default_tst$Class, predicted = model_glm_pred)


# Calculation of Confusion Matrix on training data
library(caret)
# Training data set
# train_tab = table(predicted = model_glm_pred, actual = trainingDataSet$default)
# train_tab
# train_con_mat = confusionMatrix(train_tab, positive = 1)
# train_con_mat

# Testing data set 


test_tab = table(predicted = model_glm_pred, actual = default_tst$Class)
test_tab
help("confusionMatrix")
test_con_mat = confusionMatrix(test_tab, mode = "everything", positive = "1")
test_con_mat

# Multiple Logistic Regression Case ---------------------------------------

# Fitting the model on training data set, with balance and student as predictors
model_glm = glm(formula = Class ~ Mitoses + Cell.shape , data = trainingDataSet, family = "binomial")
summary(model_glm)


# prediction on testing data 
model_glm_pred_mult = ifelse(predict(model_glm, newdata = default_tst, 
                                     type = "response") > 0.5, 1, 0)

head(model_glm_pred_mult)

# Confusion matrix on testing
testing_tab_mult = table(predicted = model_glm_pred_mult, actual = default_tst$Class)
testing_con_mat_mult = confusionMatrix(testing_tab_mult, positive = "1")

print(testing_con_mat_mult)
testing_con_mat_mult$byClass

# For graphical interpretation one can use ROC curve 
# For multiple logistic regression example

library(pROC)
# Predictions on testing data 
test_prob_mult = predict(model_glm, newdata = default_tst, type = "response")
# Drawing ROC curve for the given model
roc
test_roc_mult = roc(default_tst$Class ~ test_prob_mult, plot = T, 
                    print.auc = T)

test_roc_mult
# The value of AUC (Area under the curve), high values are indicators of good model !
as.numeric(test_roc_mult$auc)

# 2-3) Our false negative (00) value is too high. Our positive true value is less. For this reason, we could not get very accurate results.  
# 2-5)
```
Here you can notice that our model is quite successful.
2.5) We should go with our first model to reduce the error rate. As we moved from the first model to the second model, our F1 value increased at a high rate. Or another option is we can go with our second model but we have to add more variables.

# References 

Give a list of the available sources that you use while preparing your home-work
(If you use other resources, you can make a list here for checking & reproducibility). 

For instance; 

- https://www.statlearning.com/
- https://lms.tedu.edu.tr/pluginfile.php/102130/mod_resource/content/1/LogisticRegression.R
- https://towardsdatascience.com/the-f1-score-bec2bbc38aa6
- https://stackoverflow.com/